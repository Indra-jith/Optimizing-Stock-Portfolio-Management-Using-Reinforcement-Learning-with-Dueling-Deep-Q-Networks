{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Optimizing Stock Portfolio Management Using a Dueling Deep Q-Network  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b20feda4fd280367"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The project utilizes reinforcement learning, specifically a Dueling Deep Q-Network, to optimize stock portfolio management, addressing market unpredictability and enhancing automated trading decisions through data acquisition, feature engineering, and performance evaluation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d95b1f4029cc1cfc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importing the necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bfffb037ba3804e8"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:52:54.198023Z",
     "start_time": "2024-11-02T11:52:52.074168Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime, timedelta\n",
    "import torch.nn.functional as F\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "API_KEY = '769YEIDZFR0FE90Q'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:15.218354Z",
     "start_time": "2024-11-02T11:53:15.209770Z"
    }
   },
   "id": "c966ef92278c0dc",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Acquisition\n",
    "### This section uses the Alpha Vantage API to retrieve daily trading data for a variety of stocks over the past year, capturing critical metrics such as daily open/close prices, intraday high/low values, trading volume, and timestamps. Users can specify a stock symbol to dynamically fetch data relevant to their interests."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99f89f5c6f8abf9f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Fetch stock data from Alpha Vantage API\n",
    "# Define function for data acquisition\n",
    "def download_stock_data(ticker, start_date, end_date):\n",
    "    ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "    data, _ = ts.get_daily(symbol=ticker, outputsize='full')\n",
    "    \n",
    "    data = data.rename(columns={\n",
    "        '1. open': 'Open',\n",
    "        '2. high': 'High',\n",
    "        '3. low': 'Low',\n",
    "        '4. close': 'Close',\n",
    "        '5. volume': 'Volume'\n",
    "    })\n",
    "    \n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    data = data.sort_index()\n",
    "    filtered_data = data[(data.index >= pd.to_datetime(start_date)) & \n",
    "                        (data.index <= pd.to_datetime(end_date))]\n",
    "    \n",
    "    return filtered_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:16.119819Z",
     "start_time": "2024-11-02T11:53:16.098281Z"
    }
   },
   "id": "2e0da7d07120e9bd",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def compute_loss(predictions, targets):\n",
    "    targets = targets.view(-1, 1).expand_as(predictions)\n",
    "    loss = F.smooth_l1_loss(predictions, targets, reduction='none')\n",
    "    return loss.mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:16.527660Z",
     "start_time": "2024-11-02T11:53:16.518023Z"
    }
   },
   "id": "67bcb5ec453b6070",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_macd(prices, fast=12, slow=26, signal=9):\n",
    "    exp1 = prices.ewm(span=fast, adjust=False).mean()\n",
    "    exp2 = prices.ewm(span=slow, adjust=False).mean()\n",
    "    macd = exp1 - exp2\n",
    "    signal_line = macd.ewm(span=signal, adjust=False).mean()\n",
    "    histogram = macd - signal_line\n",
    "    return macd, signal_line, histogram"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:16.891464Z",
     "start_time": "2024-11-02T11:53:16.870478Z"
    }
   },
   "id": "652c99202236b91f",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_rsi(prices, period=14):\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi.fillna(50)  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:17.270651Z",
     "start_time": "2024-11-02T11:53:17.248791Z"
    }
   },
   "id": "8b53542c4b3b9233",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Preprocessing\n",
    "### To ensure data consistency and quality, preprocessing steps include handling missing values, detecting and treating outliers, and standardizing technical indicators. This prepares the data for model training and ensures stability across different market conditions.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd53b2ff48944a23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Engineering\n",
    "## This segment implements various technical indicators essential for the RL model, including:\n",
    "## - **MACD (Moving Average Convergence Divergence)**: Captures momentum and trend shifts.\n",
    "## - **RSI (Relative Strength Index)**: Signals overbought/oversold conditions.\n",
    "## - **Moving Averages and Volatility**: Offer insights into trend direction and market risk.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f4d09c48dd8352c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    df = data.copy()\n",
    "\n",
    "    \n",
    "    df['Original_Close'] = df['Close']\n",
    "\n",
    "    df['Return'] = df['Close'].pct_change().fillna(0)\n",
    "    df['MA5'] = df['Close'].rolling(window=5).mean().ffill()  \n",
    "    df['MA20'] = df['Close'].rolling(window=20).mean().ffill()  \n",
    "    df['RSI'] = calculate_rsi(df['Close'])\n",
    "    df['Volatility'] = df['Return'].rolling(window=10).std().ffill()  \n",
    "\n",
    "    df['Price_Momentum'] = (df['Close'] - df['MA20']) / df['MA20'].replace(0, np.nan)  \n",
    "\n",
    " \n",
    "    df['Above_MA5'] = (df['Close'] > df['MA5']).astype(float)\n",
    "    df['Above_MA20'] = (df['Close'] > df['MA20']).astype(float)\n",
    "\n",
    "\n",
    "    df['MACD'], df['Signal_Line'], _ = calculate_macd(df['Close'])\n",
    "\n",
    "\n",
    "    features_to_scale = ['Close', 'MA5', 'MA20', 'RSI', 'Volatility', 'Price_Momentum', 'MACD', 'Signal_Line']\n",
    "    for column in features_to_scale:\n",
    "        min_val = df[column].min()\n",
    "        max_val = df[column].max()\n",
    "        df[column] = (df[column] - min_val) / (max_val - min_val)\n",
    "        \n",
    "    df.interpolate(method='linear', inplace=True)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:18.616494Z",
     "start_time": "2024-11-02T11:53:18.597490Z"
    }
   },
   "id": "f7e863df65350e49",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.1):  \n",
    "        super(NoisyLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init = std_init\n",
    "        \n",
    "        self.weight_mu = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.register_buffer('weight_epsilon', torch.Tensor(out_features, in_features))\n",
    "        \n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.Tensor(out_features))\n",
    "        self.register_buffer('bias_epsilon', torch.Tensor(out_features))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / np.sqrt(self.in_features)\n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / np.sqrt(self.in_features))\n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / np.sqrt(self.out_features))\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        epsilon_in = self.scale_noise(self.in_features)\n",
    "        epsilon_out = self.scale_noise(self.out_features)\n",
    "        self.weight_epsilon.copy_(epsilon_out.outer(epsilon_in))\n",
    "        self.bias_epsilon.copy_(self.scale_noise(self.out_features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            return F.linear(x, self.weight_mu + self.weight_sigma * self.weight_epsilon,\n",
    "                            self.bias_mu + self.bias_sigma * self.bias_epsilon)\n",
    "        else:\n",
    "            return F.linear(x, self.weight_mu, self.bias_mu)\n",
    "    \n",
    "    @staticmethod\n",
    "    def scale_noise(size):\n",
    "        x = torch.randn(size)\n",
    "        return x.sign().mul_(x.abs().sqrt_())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:19.058360Z",
     "start_time": "2024-11-02T11:53:19.042343Z"
    }
   },
   "id": "96ecc6f126bedaf0",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dueling Deep Q-Network Design\n",
    "### This model leverages a Dueling Deep Q-Network (DDQN) with separate streams for estimating state value and action advantage. The structure includes shared feature extraction layers with specialized noise-injected transformations for robust exploration and convergence. This architecture is designed to improve generalization and decision accuracy under fluctuating market conditions.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24cd33a8b4ea77f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DuelingDQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.feature = nn.Sequential(\n",
    "            NoisyLinear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size),  \n",
    "            NoisyLinear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size)  \n",
    "        )\n",
    "        self.advantage = nn.Sequential(\n",
    "            NoisyLinear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size),  \n",
    "            NoisyLinear(hidden_size, output_size)\n",
    "        )\n",
    "        self.value = nn.Sequential(\n",
    "            NoisyLinear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_size),  \n",
    "            NoisyLinear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        advantage = self.advantage(x)\n",
    "        value = self.value(x)\n",
    "        return value + advantage - advantage.mean()\n",
    "\n",
    "    def reset_noise(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, NoisyLinear):\n",
    "                module.reset_noise()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:19.879651Z",
     "start_time": "2024-11-02T11:53:19.867651Z"
    }
   },
   "id": "157189b2940cc3cf",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Training\n",
    "### The model is trained using mini-batch learning with gradient clipping and a smooth L1 loss function for robustness. A Boltzmann exploration strategy facilitates a balance between exploring new actions and exploiting known strategies.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f895eaab167ba6f7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, X_train, y_train, epochs=100, batch_size=32):\n",
    "    model.train()\n",
    "    \n",
    "    X_train_clean = X_train.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    y_train_clean = y_train[X_train_clean.index]  \n",
    "\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(torch.tensor(X_train_clean.values, dtype=torch.float32), \n",
    "                                             torch.tensor(y_train_clean.values, dtype=torch.float32))\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        for batch in train_loader:\n",
    "            inputs, target_actions = batch\n",
    "            \n",
    "           \n",
    "            if torch.isnan(inputs).any() or torch.isinf(inputs).any() or torch.isnan(target_actions).any() or torch.isinf(target_actions).any():\n",
    "                print(\"Skipping batch due to invalid input data.\")\n",
    "                continue\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs)\n",
    "            \n",
    "            \n",
    "            if torch.isnan(predictions).any() or torch.isinf(predictions).any():\n",
    "                print(\"Skipping batch due to invalid predictions.\")\n",
    "                continue\n",
    "            \n",
    "            loss = compute_loss(predictions, target_actions)\n",
    "            \n",
    "            \n",
    "            if torch.isnan(loss) or torch.isinf(loss):\n",
    "                print(f\"Skipping batch due to invalid loss: {loss.item()}\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        \n",
    "        if num_batches > 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/num_batches:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - All batches skipped due to invalid loss\")\n",
    "        \n",
    "        \n",
    "        if num_batches == 0:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:20.698379Z",
     "start_time": "2024-11-02T11:53:20.684404Z"
    }
   },
   "id": "1c024b8430558819",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def boltzmann_exploration(q_values, temperature=1.0):\n",
    "    q_values = q_values.detach().cpu().numpy()\n",
    "    q_values = np.nan_to_num(q_values, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    exp_q = np.exp(q_values / temperature)\n",
    "    probs = exp_q / np.sum(exp_q)\n",
    "    action = np.random.choice(len(probs), p=probs)\n",
    "    return action"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:21.123549Z",
     "start_time": "2024-11-02T11:53:21.102473Z"
    }
   },
   "id": "ee929ac9c415bc23",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.02):\n",
    "    excess_returns = returns - risk_free_rate / 252  # Assuming 252 trading days in a year\n",
    "    \n",
    "   \n",
    "    mean_excess_return = excess_returns.mean()\n",
    "    std_excess_return = excess_returns.std()\n",
    "\n",
    "    \n",
    "    if std_excess_return == 0:\n",
    "        if mean_excess_return > 0:\n",
    "            return np.inf  \n",
    "        elif mean_excess_return < 0:\n",
    "            return -np.inf  \n",
    "        else:\n",
    "            return 0.0  \n",
    "\n",
    "    # Compute Sharpe Ratio\n",
    "    sharpe_ratio = np.sqrt(252) * mean_excess_return / std_excess_return\n",
    "    return sharpe_ratio\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:21.563972Z",
     "start_time": "2024-11-02T11:53:21.546660Z"
    }
   },
   "id": "161401cbde7f7eb3",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance Evaluation\n",
    "### The final model's effectiveness is evaluated using metrics such as the Sharpe Ratio for risk-adjusted returns and Maximum Drawdown for downside risk assessment. A portfolio simulation with transaction cost considerations is used to mimic real-world trading conditions.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbae20f5770e80c8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def simulate_portfolio(model, test_data, initial_portfolio=5000, temperature=1.0):\n",
    "    model.eval()\n",
    "    portfolio_value = initial_portfolio\n",
    "    portfolio_history = []\n",
    "    shares_held = 0\n",
    "    daily_returns = []\n",
    "    \n",
    "    print(\"\\n=== Last 7 Days Portfolio Simulation ===\")\n",
    "    print(f\"Initial Portfolio Value: ₹{portfolio_value:.2f}\")\n",
    "    \n",
    "    for i in range(len(test_data)-1):\n",
    "        current_price = test_data['Original_Close'].iloc[i]\n",
    "        next_price = test_data['Original_Close'].iloc[i+1]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            features = ['Close', 'MA5', 'MA20', 'RSI', 'Volatility', 'Price_Momentum', 'Above_MA5', 'Above_MA20', 'MACD', 'Signal_Line']\n",
    "            current_data = torch.FloatTensor(test_data.iloc[i][features].values)\n",
    "            q_values = model(current_data.unsqueeze(0)).squeeze()\n",
    "            action = boltzmann_exploration(q_values, temperature)\n",
    "        \n",
    "        # More aggressive trading strategy with transaction costs\n",
    "        transaction_cost = 0.001  # 0.1% transaction cost\n",
    "        if action == 1:  # Buy signal\n",
    "            if shares_held == 0:\n",
    "                shares_to_buy = (portfolio_value * (1 - transaction_cost)) // current_price\n",
    "                shares_held = shares_to_buy\n",
    "                portfolio_value -= shares_to_buy * current_price * (1 + transaction_cost)\n",
    "                trading_action = f\"BUY {shares_to_buy} shares at ₹{current_price:.2f}\"\n",
    "            else:\n",
    "                trading_action = \"HOLD (Already invested)\"\n",
    "        elif action == 2:  # Sell signal\n",
    "            if shares_held > 0:\n",
    "                portfolio_value += shares_held * current_price * (1 - transaction_cost)\n",
    "                trading_action = f\"SELL {shares_held} shares at ₹{current_price:.2f}\"\n",
    "                shares_held = 0\n",
    "            else:\n",
    "                trading_action = \"HOLD (No shares to sell)\"\n",
    "        else:\n",
    "            trading_action = \"HOLD\"\n",
    "        \n",
    "        if shares_held > 0:\n",
    "            portfolio_value = shares_held * current_price\n",
    "        \n",
    "        daily_return = (portfolio_value - initial_portfolio) / initial_portfolio\n",
    "        daily_returns.append(daily_return)\n",
    "        \n",
    "        print(f\"\\nDay {i+1}: {test_data.index[i].strftime('%Y-%m-%d')}\")\n",
    "        print(f\"Stock Price: ₹{current_price:.2f}\")\n",
    "        print(f\"Action Taken: {trading_action}\")\n",
    "        print(f\"Portfolio Value: ₹{portfolio_value:.2f}\")\n",
    "        \n",
    "        portfolio_history.append({\n",
    "            'date': test_data.index[i],\n",
    "            'portfolio_value': portfolio_value,\n",
    "            'action': trading_action,\n",
    "            'price': current_price,\n",
    "            'shares_held': shares_held\n",
    "        })\n",
    "    \n",
    "    total_return = ((portfolio_value - initial_portfolio) / initial_portfolio) * 100\n",
    "    sharpe_ratio = calculate_sharpe_ratio(pd.Series(daily_returns))\n",
    "    \n",
    "    print(f\"\\n=== Simulation Results ===\")\n",
    "    print(f\"Starting Portfolio: ₹{initial_portfolio:.2f}\")\n",
    "    print(f\"Final Portfolio: ₹{portfolio_value:.2f}\")\n",
    "    print(f\"Total Return: {total_return:+.2f}%\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "    \n",
    "    return portfolio_value, portfolio_history, sharpe_ratio"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:22.419762Z",
     "start_time": "2024-11-02T11:53:22.408737Z"
    }
   },
   "id": "f1c2697fff76fb8f",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_recommendation(model, current_data, temperature=1.0):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Extract features for the current data\n",
    "    features = ['Close', 'MA5', 'MA20', 'RSI', 'Volatility', 'Price_Momentum', 'Above_MA5', 'Above_MA20', 'MACD', 'Signal_Line']\n",
    "    current_features = torch.FloatTensor(current_data[features].values).unsqueeze(0)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        q_values = model(current_features).squeeze() \n",
    "        action_probabilities = np.nan_to_num(np.exp(q_values.cpu().numpy() / temperature))\n",
    "        action_probabilities /= action_probabilities.sum()  \n",
    "        action = np.random.choice(len(action_probabilities), p=action_probabilities) \n",
    "\n",
    "    action_mapping = {0: \"SELL\", 1: \"HOLD\", 2: \"BUY\"}\n",
    "    return action_mapping[action], action_probabilities"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:22.878243Z",
     "start_time": "2024-11-02T11:53:22.867240Z"
    }
   },
   "id": "ee752abb9c01905c",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose a stock from the following list:\n",
      "Reliance Global Group Inc (RELI)\n",
      "Infosys (INFY)\n",
      "HDFC Bank (HDB)\n",
      "ICICI Bank (IBN)\n",
      "Apple Inc. (AAPL)\n",
      "Microsoft Corp. (MSFT)\n",
      "Amazon.com Inc. (AMZN)\n",
      "Alphabet Inc. (Google) (GOOGL)\n",
      "Tesla Inc. (TSLA)\n",
      "Nvidia Corp. (NVDA)\n",
      "Coca-Cola Company (KO)\n",
      "You selected: AAPL\n"
     ]
    }
   ],
   "source": [
    "# List of famous stocks and their symbols\n",
    "stocks = {\n",
    "    \"Reliance Global Group Inc\": \"RELI\",\n",
    "    \"Infosys\": \"INFY\",\n",
    "    \"HDFC Bank\": \"HDB\",\n",
    "    \"ICICI Bank\": \"IBN\",\n",
    "    \"Apple Inc.\": \"AAPL\",\n",
    "    \"Microsoft Corp.\": \"MSFT\",\n",
    "    \"Amazon.com Inc.\": \"AMZN\",\n",
    "    \"Alphabet Inc. (Google)\": \"GOOGL\",\n",
    "    \"Tesla Inc.\": \"TSLA\",\n",
    "    \"Nvidia Corp.\": \"NVDA\",\n",
    "    \"Coca-Cola Company\": \"KO\"\n",
    "}\n",
    "\n",
    "# Prompt user for input\n",
    "print(\"Please choose a stock from the following list:\")\n",
    "for stock, symbol in stocks.items():\n",
    "    print(f\"{stock} ({symbol})\")\n",
    "\n",
    "# Get user input\n",
    "ticker = input(\"Enter the stock symbol (e.g., AAPL, RELIANCE): \").strip().upper()\n",
    "\n",
    "# Validate user input\n",
    "if ticker in stocks.values():\n",
    "    print(f\"You selected: {ticker}\")\n",
    "else:\n",
    "    print(\"Invalid stock symbol. Please check the symbol and try again.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:53:28.832451Z",
     "start_time": "2024-11-02T11:53:23.309961Z"
    }
   },
   "id": "8d580afaac930af0",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stock Trading Analysis ===\n",
      "Analyzing data from 2023-11-03 to 2024-11-01\n",
      "\n",
      "Training model on historical data...\n",
      "Epoch 1/100, Loss: 0.0965\n",
      "Epoch 2/100, Loss: 0.0341\n",
      "Epoch 3/100, Loss: 0.0101\n",
      "Epoch 4/100, Loss: 0.0045\n",
      "Epoch 5/100, Loss: 0.0030\n",
      "Epoch 6/100, Loss: 0.0012\n",
      "Epoch 7/100, Loss: 0.0015\n",
      "Epoch 8/100, Loss: 0.0009\n",
      "Epoch 9/100, Loss: 0.0007\n",
      "Epoch 10/100, Loss: 0.0005\n",
      "Epoch 11/100, Loss: 0.0005\n",
      "Epoch 12/100, Loss: 0.0007\n",
      "Epoch 13/100, Loss: 0.0004\n",
      "Epoch 14/100, Loss: 0.0003\n",
      "Epoch 15/100, Loss: 0.0003\n",
      "Epoch 16/100, Loss: 0.0005\n",
      "Epoch 17/100, Loss: 0.0004\n",
      "Epoch 18/100, Loss: 0.0003\n",
      "Epoch 19/100, Loss: 0.0002\n",
      "Epoch 20/100, Loss: 0.0003\n",
      "Epoch 21/100, Loss: 0.0004\n",
      "Epoch 22/100, Loss: 0.0006\n",
      "Epoch 23/100, Loss: 0.0007\n",
      "Epoch 24/100, Loss: 0.0009\n",
      "Epoch 25/100, Loss: 0.0012\n",
      "Epoch 26/100, Loss: 0.0008\n",
      "Epoch 27/100, Loss: 0.0005\n",
      "Epoch 28/100, Loss: 0.0004\n",
      "Epoch 29/100, Loss: 0.0003\n",
      "Epoch 30/100, Loss: 0.0003\n",
      "Epoch 31/100, Loss: 0.0003\n",
      "Epoch 32/100, Loss: 0.0002\n",
      "Epoch 33/100, Loss: 0.0002\n",
      "Epoch 34/100, Loss: 0.0002\n",
      "Epoch 35/100, Loss: 0.0002\n",
      "Epoch 36/100, Loss: 0.0002\n",
      "Epoch 37/100, Loss: 0.0002\n",
      "Epoch 38/100, Loss: 0.0002\n",
      "Epoch 39/100, Loss: 0.0002\n",
      "Epoch 40/100, Loss: 0.0001\n",
      "Epoch 41/100, Loss: 0.0002\n",
      "Epoch 42/100, Loss: 0.0004\n",
      "Epoch 43/100, Loss: 0.0003\n",
      "Epoch 44/100, Loss: 0.0003\n",
      "Epoch 45/100, Loss: 0.0004\n",
      "Epoch 46/100, Loss: 0.0005\n",
      "Epoch 47/100, Loss: 0.0002\n",
      "Epoch 48/100, Loss: 0.0002\n",
      "Epoch 49/100, Loss: 0.0002\n",
      "Epoch 50/100, Loss: 0.0002\n",
      "Epoch 51/100, Loss: 0.0002\n",
      "Epoch 52/100, Loss: 0.0002\n",
      "Epoch 53/100, Loss: 0.0001\n",
      "Epoch 54/100, Loss: 0.0002\n",
      "Epoch 55/100, Loss: 0.0001\n",
      "Epoch 56/100, Loss: 0.0001\n",
      "Epoch 57/100, Loss: 0.0002\n",
      "Epoch 58/100, Loss: 0.0002\n",
      "Epoch 59/100, Loss: 0.0002\n",
      "Epoch 60/100, Loss: 0.0002\n",
      "Epoch 61/100, Loss: 0.0003\n",
      "Epoch 62/100, Loss: 0.0002\n",
      "Epoch 63/100, Loss: 0.0003\n",
      "Epoch 64/100, Loss: 0.0003\n",
      "Epoch 65/100, Loss: 0.0006\n",
      "Epoch 66/100, Loss: 0.0007\n",
      "Epoch 67/100, Loss: 0.0006\n",
      "Epoch 68/100, Loss: 0.0007\n",
      "Epoch 69/100, Loss: 0.0003\n",
      "Epoch 70/100, Loss: 0.0003\n",
      "Epoch 71/100, Loss: 0.0003\n",
      "Epoch 72/100, Loss: 0.0002\n",
      "Epoch 73/100, Loss: 0.0002\n",
      "Epoch 74/100, Loss: 0.0003\n",
      "Epoch 75/100, Loss: 0.0004\n",
      "Epoch 76/100, Loss: 0.0002\n",
      "Epoch 77/100, Loss: 0.0004\n",
      "Epoch 78/100, Loss: 0.0001\n",
      "Epoch 79/100, Loss: 0.0002\n",
      "Epoch 80/100, Loss: 0.0002\n",
      "Epoch 81/100, Loss: 0.0004\n",
      "Epoch 82/100, Loss: 0.0003\n",
      "Epoch 83/100, Loss: 0.0002\n",
      "Epoch 84/100, Loss: 0.0002\n",
      "Epoch 85/100, Loss: 0.0003\n",
      "Epoch 86/100, Loss: 0.0002\n",
      "Epoch 87/100, Loss: 0.0002\n",
      "Epoch 88/100, Loss: 0.0005\n",
      "Epoch 89/100, Loss: 0.0006\n",
      "Epoch 90/100, Loss: 0.0005\n",
      "Epoch 91/100, Loss: 0.0002\n",
      "Epoch 92/100, Loss: 0.0005\n",
      "Epoch 93/100, Loss: 0.0006\n",
      "Epoch 94/100, Loss: 0.0003\n",
      "Epoch 95/100, Loss: 0.0002\n",
      "Epoch 96/100, Loss: 0.0004\n",
      "Epoch 97/100, Loss: 0.0008\n",
      "Epoch 98/100, Loss: 0.0007\n",
      "Epoch 99/100, Loss: 0.0003\n",
      "Epoch 100/100, Loss: 0.0003\n",
      "\n",
      "Simulating portfolio performance...\n",
      "\n",
      "=== Last 7 Days Portfolio Simulation ===\n",
      "Initial Portfolio Value: ₹5000.00\n",
      "\n",
      "Day 1: 2024-10-24\n",
      "Stock Price: ₹230.57\n",
      "Action Taken: BUY 21.0 shares at ₹230.57\n",
      "Portfolio Value: ₹4841.97\n",
      "\n",
      "Day 2: 2024-10-25\n",
      "Stock Price: ₹231.41\n",
      "Action Taken: HOLD\n",
      "Portfolio Value: ₹4859.61\n",
      "\n",
      "Day 3: 2024-10-28\n",
      "Stock Price: ₹233.40\n",
      "Action Taken: SELL 21.0 shares at ₹233.40\n",
      "Portfolio Value: ₹9756.11\n",
      "\n",
      "Day 4: 2024-10-29\n",
      "Stock Price: ₹233.67\n",
      "Action Taken: BUY 41.0 shares at ₹233.67\n",
      "Portfolio Value: ₹9580.47\n",
      "\n",
      "Day 5: 2024-10-30\n",
      "Stock Price: ₹230.10\n",
      "Action Taken: HOLD (Already invested)\n",
      "Portfolio Value: ₹9434.10\n",
      "\n",
      "Day 6: 2024-10-31\n",
      "Stock Price: ₹225.91\n",
      "Action Taken: HOLD (Already invested)\n",
      "Portfolio Value: ₹9262.31\n",
      "\n",
      "=== Simulation Results ===\n",
      "Starting Portfolio: ₹5000.00\n",
      "Final Portfolio: ₹9262.31\n",
      "Total Return: +85.25%\n",
      "Sharpe Ratio: 19.4618\n"
     ]
    }
   ],
   "source": [
    "end_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "start_date = (datetime.now() - timedelta(days=365)).strftime('%Y-%m-%d')\n",
    "        \n",
    "\n",
    "print(\"\\n=== Stock Trading Analysis ===\")\n",
    "print(f\"Analyzing data from {start_date} to {end_date}\")\n",
    "stock_data = download_stock_data(ticker, start_date, end_date)\n",
    "processed_data = preprocess_data(stock_data)\n",
    "\n",
    "\n",
    "test_data = processed_data.tail(7)  # selects the last 6 rows from processed_data\n",
    "train_data = processed_data.iloc[:-7]  # uses all but the last 6 rows for training\n",
    "\n",
    "# Update feature and target variable definitions as before\n",
    "features = ['Close', 'MA5', 'MA20', 'RSI', 'Volatility', 'Price_Momentum', 'Above_MA5', 'Above_MA20', 'MACD', 'Signal_Line']   \n",
    "X_train = train_data[features]\n",
    "y_train = train_data['Return']\n",
    "\n",
    "input_size = len(features)\n",
    "hidden_size = 64  \n",
    "output_size = 3  # Buy, Hold, Sell\n",
    "model = DuelingDQN(input_size, hidden_size, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5) \n",
    "\n",
    "print(\"\\nTraining model on historical data...\")\n",
    "train_model(model, optimizer, X_train, y_train, epochs=100, batch_size=32)\n",
    "\n",
    "print(\"\\nSimulating portfolio performance...\")\n",
    "final_portfolio_value, portfolio_history, sharpe_ratio = simulate_portfolio(model, test_data, initial_portfolio=5000, temperature=0.5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-02T11:54:33.299431Z",
     "start_time": "2024-11-02T11:54:28.216087Z"
    }
   },
   "id": "eadd626f0f595b3c",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "13883bb9bd5f3496"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
